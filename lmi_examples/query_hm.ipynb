{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import chromadb\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LVD Filtering Benchmark on Keyword dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bbec181ba889923"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebooks allows for conducting basci experoments and visualizations on match keyword filtering dataset.\n",
    "The notebook was orginally designed for [H&M](https://github.com/qdrant/ann-filtering-benchmark-datasets?tab=readme-ov-file) dataset encoded with Efficientnet for experiments. Original the data is from [Kaggle](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3926442d4407dbe6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d170daebdff33cc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_name = \"random_keywords_10k\"\n",
    "dir_path = f\"data/{dataset_name}/\"\n",
    "vectors_path = dir_path + \"vectors.npy\"\n",
    "payloads_path = dir_path + \"payloads.jsonl\"\n",
    "tests_path = dir_path + \"tests.jsonl\"\n",
    "\n",
    "# Load vectors as numpy array\n",
    "vectors = np.load(vectors_path)\n",
    "\n",
    "# Load payloads.jsonl as python list\n",
    "with open(payloads_path, 'r') as file:\n",
    "    payloads = [json.loads(line) for line in file]\n",
    "\n",
    "# Load tests.jsonl as python list\n",
    "with open(tests_path, 'r') as file:\n",
    "    tests = [json.loads(line) for line in file]\n",
    "\n",
    "(vectors.shape, len(payloads), len(tests))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25d6fedc0af76997"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check whether filter have same format and preprocess dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef2096dabd882bb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_payloads(payloads):\n",
    "    \"\"\"\n",
    "    Preprocess payloads replacing None values with the string 'None'.\n",
    "    :param payloads: A list of payload entries\n",
    "    :return: The preprocessed list of payloads\n",
    "    \"\"\"\n",
    "    for payload in payloads:\n",
    "        for key, value in payload.items():\n",
    "            if value is None:\n",
    "                payload[key] = 'None'\n",
    "\n",
    "preprocess_payloads(payloads)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "683e0fc89272076f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Metadata Example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ad2bff653912079"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(json.dumps(payloads[0], indent=4, sort_keys=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12b5785e664424b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Query Restrictivness Distribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c9107e202e54b9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def apply_condition(payloads, condition):\n",
    "    \"\"\"\n",
    "    Apply a given condition to the list of payloads and return the filtered list.\n",
    "    \"\"\"\n",
    "    filtered_payloads = []\n",
    "    filtered_payloads_ids = []\n",
    "\n",
    "    # Check if the condition is 'and' or 'or' and process accordingly\n",
    "    if 'and' in condition:\n",
    "        for i, payload in enumerate(payloads):\n",
    "            if all(payload.get(key, None) == val['match']['value'] for cond in condition['and'] for key, val in cond.items()):\n",
    "                filtered_payloads.append(payload)\n",
    "                filtered_payloads_ids.append(str(i))\n",
    "    elif 'or' in condition:\n",
    "        for i, payload in enumerate(payloads):\n",
    "            if any(payload.get(key, None) == val['match']['value'] for cond in condition['or'] for key, val in cond.items()):\n",
    "                filtered_payloads.append(payload)\n",
    "                filtered_payloads_ids.append(str(i))\n",
    "\n",
    "    return filtered_payloads, filtered_payloads_ids"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b7d6dd0f0379def"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratios = []\n",
    "\n",
    "for condition in [tests[i]['conditions'] for i in range(len(tests))]:\n",
    "    filtered_payloads, _ = apply_condition(payloads, condition)\n",
    "    ratio = len(filtered_payloads) / len(payloads)\n",
    "    ratios.append(ratio)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b31bafa93264986"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_ratios(ratios):\n",
    "    # Define the intervals (bins)\n",
    "    bins = np.linspace(0.0, 0.5, num=11)  # 11 edges for 10 bins\n",
    "    \n",
    "    # Count the number of ratios in each bin\n",
    "    hist, _ = np.histogram(ratios, bins)\n",
    "    \n",
    "    # Plotting the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(bins[:-1], hist, width=0.05, align='edge', edgecolor='black')\n",
    "    \n",
    "    # Setting the x-axis limits\n",
    "    plt.xlim(0, 0.5)\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Filter Restrictiveness')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Filter Restrictiveness Distribution')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "835fa8e1d570c4ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_ratios(ratios)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5076fbf9695e8eb6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lest_restrictive_condition = tests[np.argmax(ratios)]['conditions']\n",
    "_, least_restrictive_condition_ids = apply_condition(payloads, lest_restrictive_condition)\n",
    "print('Condition with the lowest restrictivness: \\n', lest_restrictive_condition)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4abd0fb7d06cc701"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34e21cbea68796f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configuration from SISAP 2023 Indexing Challenge - LMI except n_categories\n",
    "index_configuraiton = {\n",
    "    \"lmi:epochs\": \"[200]\",\n",
    "    \"lmi:model_types\": \"['MLP-4']\",\n",
    "    \"lmi:lrs\": \"[0.01]\",\n",
    "    \"lmi:n_categories\": \"[10]\",\n",
    "    \"lmi:kmeans\": \"{'verbose': False, 'seed': 2023, 'min_points_per_centroid': 100}\",\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56222316360dc375"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "\n",
    "collection_name = \"synthetic_collection\"\n",
    "collection = client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata=index_configuraiton\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9509da366caa8d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data in batches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e24b81111d7d8e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 40000 # can large batch cause slow down?\n",
    "dataset_size = vectors.shape[0]\n",
    "for i in tqdm(range(0, dataset_size, batch_size), desc=\"Adding documents\"):\n",
    "    collection.add(\n",
    "        embeddings=vectors[i: i + batch_size].tolist(),\n",
    "        metadatas=payloads[i: i + batch_size],\n",
    "        ids=[\n",
    "            str(i) for i in range(i, min(i + batch_size, dataset_size))\n",
    "        ]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0fbc9db45050bb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "bucket_assignment = collection.build_index()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "261bf6e1c28f8138"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_bucket_items(data, highlight_ids=None):\n",
    "    \"\"\"\n",
    "    Plot the number of items in each bucket, with an optional overlay of highlighted items.\n",
    "\n",
    "    Parameters:\n",
    "    data (DataFrame): The data frame containing the 'id', 'bucket', and 'cluster' columns.\n",
    "    highlight_ids (list, optional): List of ids to highlight in the visualization.\n",
    "    \"\"\"\n",
    "    # Count the total number of items in each bucket\n",
    "    bucket_counts = data.groupby('bucket_str').size()\n",
    "    plot_data = bucket_counts.reset_index(name='count')\n",
    "\n",
    "    # Create the bar plot for total items\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    total_bars = sns.barplot(data=plot_data, x='bucket_str', y='count')\n",
    "\n",
    "    # If highlight_ids is provided, overlay highlighted bars\n",
    "    if highlight_ids is not None:\n",
    "        # Filter data to include only highlighted ids\n",
    "        highlighted_data = data[data['id'].isin(highlight_ids)]\n",
    "        highlighted_counts = highlighted_data.groupby('bucket_str').size()\n",
    "        highlighted_plot_data = highlighted_counts.reset_index(name='count')\n",
    "\n",
    "        # Create overlay bar plot for highlighted items\n",
    "        sns.barplot(data=highlighted_plot_data, x='bucket_str', y='count', color='red', alpha=0.7)\n",
    "\n",
    "        # Create custom legend\n",
    "        legend_elements = [Patch(facecolor=total_bars.patches[0].get_facecolor(), label='Total Items in Bucket'),\n",
    "                           Patch(facecolor='red', alpha=0.5, label='Items Satisfying Condition in Bucket')]\n",
    "        plt.legend(handles=legend_elements)\n",
    "\n",
    "    if highlight_ids is not None:\n",
    "        plt.title('Number of Items in Each Bucket For Query With Lowest Restrictiveness')\n",
    "    else:\n",
    "        plt.title('Number of Items in Each Bucket')\n",
    "    plt.xlabel('Bucket')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    # Annotate each bar with the count of elements\n",
    "    for p in total_bars.patches:\n",
    "        bar_height = int(p.get_height())\n",
    "        if bar_height > 0:  # Only annotate bars with a height greater than zero\n",
    "            total_bars.annotate(f'{bar_height}', (p.get_x() + p.get_width() / 2., bar_height),\n",
    "                                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
    "                                textcoords='offset points')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7ed2aaacd2e28b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_buckets = pd.DataFrame([str(i) for i in range(vectors.shape[0])], columns=[\"id\"])\n",
    "data_buckets['bucket'] = data_buckets['id'].map(lambda x: list(bucket_assignment.get(x, [])))\n",
    "data_buckets['bucket_str'] = data_buckets['bucket'].apply(lambda x: str(x))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edae278afa9c25fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bucket_items(data_buckets)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f679bfb637d0049c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bucket_items(data_buckets, highlight_ids=least_restrictive_condition_ids)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "729fcbd522ea5293"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query Database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42b82cb6b26f19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('\\n ------- Query Example ------- \\n')\n",
    "print('Vector: ' + str(tests[0]['query'][:5]).rstrip(\"]\") + \", ... ]\")\n",
    "print('Constraint: ', tests[0]['conditions'])\n",
    "\n",
    "print('\\n ------- Ground Truth For The Query ------- \\n')\n",
    "print('Ground truth: ', tests[0]['closest_ids'])\n",
    "print('Closest scores: '+ str(tests[0]['closest_scores'][:5]).rstrip(\"]\") + \", ... ]\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdea2242aad69bc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_condition(input_condition):\n",
    "    output_condition = {}\n",
    "\n",
    "    # Iterate through the keys ('and'/'or') and their list of conditions\n",
    "    for key, conditions in input_condition.items():\n",
    "        output_key = f\"${key}\"\n",
    "        output_conditions = []\n",
    "\n",
    "        # Process each condition in the list\n",
    "        for condition in conditions:\n",
    "            for field, match in condition.items():\n",
    "                # Assume 'match' is always present as per input format\n",
    "                value = match['match']['value']\n",
    "                output_conditions.append({field: value})\n",
    "\n",
    "        # If there's only one condition in 'and'/'or', do not use '$and'/'$or'\n",
    "        if len(output_conditions) == 1 and key in ['and', 'or']:\n",
    "            output_condition = output_conditions[0]\n",
    "        else:\n",
    "            output_condition[output_key] = output_conditions\n",
    "\n",
    "    return output_condition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8293a892b0f2a23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_condition_to_simple_dict(condition):\n",
    "    key = list(condition['and'][0].keys())[0]  # Extract key from the first item\n",
    "    value = condition['and'][0][key]['match']['value']  # Extract value from the nested structure\n",
    "    return {key: value}\n",
    "\n",
    "def calculate_precision(relevant_ids, retrieved_ids):\n",
    "    # If there are no relevant IDs and no retrieved IDs, precision is 1\n",
    "    if len(relevant_ids) == 0 and len(retrieved_ids) == 0:\n",
    "        return 1\n",
    "    \n",
    "    retrieved_ids = set(map(int, retrieved_ids))\n",
    "    relevant_ids = set(relevant_ids)\n",
    "    true_positives = len(relevant_ids & retrieved_ids)\n",
    "    \n",
    "    return true_positives / len(retrieved_ids) if retrieved_ids else 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87eaac39521a7c7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def perform_queries(total_queries, constraint_weight, bruteforce_threshold, n_buckets=1, search_until_bucket_not_empty=False):\n",
    "    queries_results = []\n",
    "    \n",
    "    for query_id in range(total_queries):\n",
    "        test_query_object = tests[query_id]\n",
    "        start = time.time()\n",
    "        results = collection.query(\n",
    "            query_embeddings=test_query_object[\"query\"],\n",
    "            include=[\"metadatas\"],\n",
    "            where=convert_condition(test_query_object[\"conditions\"]),\n",
    "            n_results=25,\n",
    "            n_buckets=n_buckets,\n",
    "            constraint_weight=constraint_weight,\n",
    "            bruteforce_threshold=bruteforce_threshold,\n",
    "            search_until_bucket_not_empty=search_until_bucket_not_empty\n",
    "        )\n",
    "        end = time.time()\n",
    "        wall_time = end - start\n",
    "        results['wall_time'] = wall_time\n",
    "        \n",
    "        queries_results.append(results)\n",
    "        \n",
    "    return queries_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1152b234426aebc1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constraint Parameter Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fbdef6d3bed8ad6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def percision_per_restrictiveness(vis_queries_filter_restrictiveness, vis_queries_precision_lmi, constrint_weight, bruteforce_threshold):\n",
    "    # Create a DataFrame for easy plotting\n",
    "    data = pd.DataFrame({\n",
    "        'Filter Restrictiveness': vis_queries_filter_restrictiveness,\n",
    "        'Precision LMI': vis_queries_precision_lmi\n",
    "    })\n",
    "    \n",
    "    bin_edges = np.arange(-0.05, 0.55, 0.1) # six bins centered around 0.0, 0.1, ..., 0.5\n",
    "    \n",
    "    # Cut the data into bins\n",
    "    bin_indices = pd.cut(data['Filter Restrictiveness'], bins=bin_edges, include_lowest=True, labels=False)\n",
    "    \n",
    "    # Map each bin index to the corresponding median Precision LMI\n",
    "    bin_medians = data.groupby(bin_indices)['Precision LMI'].mean().values\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot the histogram in the first subplot\n",
    "    ax1.bar(bin_edges[:-1], bin_medians, width=0.1, align='edge', edgecolor='black')\n",
    "    ax1.set_xlabel('Filter Restrictiveness')\n",
    "    ax1.set_ylabel('Mean Precision LMI')\n",
    "    ax1.set_title(f'Median Precision LMI by Filter Restrictiveness With CW {constrint_weight} and BT {bruteforce_threshold}')\n",
    "\n",
    "    # Plot the scatter plot in the second subplot\n",
    "    ax2.scatter(data['Filter Restrictiveness'], data['Precision LMI'], alpha=0.7)\n",
    "    ax2.set_xlabel('Filter Restrictiveness')\n",
    "    ax2.set_ylabel('Precision LMI')\n",
    "    ax2.set_title('Scatter Plot of Precision LMI vs Filter Restrictiveness')\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc45b49aa037d42d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cw_test = {}\n",
    "cw_grid = [-1, 0.5, 0.25, 0.75]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e041e19432de8d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bruteforce_for_cws = 0.0\n",
    "\n",
    "for cw in cw_grid:\n",
    "    vis_queries_evaluated = perform_queries(100, cw, bruteforce_for_cws, 2, False)\n",
    "    \n",
    "    vis_lmi_indexes = []\n",
    "    \n",
    "    for i, result in enumerate(vis_queries_evaluated):\n",
    "        if not result['bruteforce_used']:\n",
    "            vis_lmi_indexes.append(i)\n",
    "    \n",
    "    # I want to evaluate only queries that used LMI\n",
    "    # With bruteforce_for_cws=0.0 this will always pass\n",
    "    assert len(vis_lmi_indexes) >= 100\n",
    "    # vis_lmi_indexes = vis_lmi_indexes[:100]\n",
    "    \n",
    "    vis_queries_precision = list((calculate_precision(tests[i][\"closest_ids\"], result['ids'][0]) for i, result in enumerate(vis_queries_evaluated)))\n",
    "    vis_queries_filter_restrictiveness = list( result['filter_restrictiveness'] for result in vis_queries_evaluated)\n",
    "    \n",
    "    vis_queries_precision_lmi = [vis_queries_precision[i] for i in vis_lmi_indexes]\n",
    "    vis_queries_filter_restrictiveness = [vis_queries_filter_restrictiveness[i] for i in vis_lmi_indexes]\n",
    "    \n",
    "    percision_per_restrictiveness(vis_queries_filter_restrictiveness, vis_queries_precision_lmi, cw, 0.0)\n",
    "    cw_test[f\"cw: {cw}\"] = sum(vis_queries_precision_lmi)/len(vis_queries_precision_lmi)\n",
    "    \n",
    "# Extracting keys and values\n",
    "keys = list(cw_test.keys())\n",
    "values = list(cw_test.values())\n",
    "\n",
    "# Creating the bar chart\n",
    "plt.bar(keys, values, color=['blue', 'green', 'purple', 'orange'])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Hyperparameter')\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('Constraint weight')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "151802d543acad9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cw_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "573b895505ca5f69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bruteforce Threshold Parameter Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d816efe7e106811c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vis_queries_evaluated = perform_queries(100, 0, 0, 1, True)\n",
    "\n",
    "vis_lmi_indexes = []\n",
    "\n",
    "for i, result in enumerate(vis_queries_evaluated):\n",
    "    if not result['bruteforce_used']:\n",
    "        vis_lmi_indexes.append(i)\n",
    "\n",
    "# I want to evaluate only queries that used LMI\n",
    "# With bruteforce_for_cws=0.0 this will always pass\n",
    "assert len(vis_lmi_indexes) >= 100\n",
    "# vis_lmi_indexes = vis_lmi_indexes[:100]\n",
    "\n",
    "vis_queries_wall_time = list( result['wall_time'] for result in vis_queries_evaluated)\n",
    "vis_queries_wall_time = [vis_queries_wall_time[i] for i in vis_lmi_indexes]\n",
    "\n",
    "vis_queries_filter_restrictiveness = list( result['filter_restrictiveness'] for result in vis_queries_evaluated)\n",
    "vis_queries_filter_restrictiveness = [vis_queries_filter_restrictiveness[i] for i in vis_lmi_indexes]\n",
    "\n",
    "print('Total time of queries: ', sum(vis_queries_wall_time))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a221b7b969312ed9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_wall_time_per_restrictiveness = pd.DataFrame({\n",
    "    'Filter Restrictiveness': vis_queries_filter_restrictiveness,\n",
    "    'Wall Time': vis_queries_wall_time\n",
    "})\n",
    "\n",
    "bin_edges = np.arange(-0.05, 0.55, 0.1) # six bins centered around 0.0, 0.1, ..., 0.5\n",
    "\n",
    "# Cut the data into bins\n",
    "bin_indices = pd.cut(data_wall_time_per_restrictiveness['Filter Restrictiveness'], bins=bin_edges, include_lowest=True, labels=False)\n",
    "\n",
    "# Map each bin index to the corresponding median Precision LMI\n",
    "bin_medians = data_wall_time_per_restrictiveness.groupby(bin_indices)['Wall Time'].mean().values\n",
    "\n",
    "# Plot the histogram\n",
    "plt.bar(bin_edges[:-1], bin_medians, width=0.1, align='edge', edgecolor='black')\n",
    "plt.xlabel('Filter Restrictiveness')\n",
    "plt.ylabel('Mean Wall Time')\n",
    "plt.title(f'Median Wall Time by Filter Restrictiveness')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9c2d87069e115af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating scatter plot using DataFrame\n",
    "plt.scatter(data_wall_time_per_restrictiveness['Filter Restrictiveness'], data_wall_time_per_restrictiveness['Wall Time'])\n",
    "plt.xlabel('Filter Restrictiveness')\n",
    "plt.ylabel('Wall Time (seconds)')\n",
    "plt.title('Scatter Plot of Filter Restrictiveness vs Wall Time')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad1a91a6c9c0e7eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Benchmark Constraint Search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e367d7ff08b7366"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "total_queries = 100\n",
    "\n",
    "start = time.time()\n",
    "queries_results = perform_queries(total_queries, -1, 0.15, 2)\n",
    "end = time.time()\n",
    "wall_time = end - start"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b627775f826c435"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ca448138a514f1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "queries_precision = list((calculate_precision(tests[i][\"closest_ids\"], result['ids'][0]) for i, result in enumerate(queries_results)))\n",
    "lmi_queries_indexes = []\n",
    "for i, result in enumerate(queries_results):\n",
    "    if not result['bruteforce_used']:\n",
    "        lmi_queries_indexes.append(i)\n",
    "lmi_used_num = len(lmi_queries_indexes)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa0a70fa21da6717"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Number of times LMI was used', len(lmi_queries_indexes))\n",
    "bruteforce_used = total_queries - lmi_used_num\n",
    "\n",
    "lmi_precisions = [queries_precision[i] for i in lmi_queries_indexes]\n",
    "if len(lmi_precisions) > 0:\n",
    "    print('lmi_average_precision', sum(lmi_precisions) / len(lmi_precisions))\n",
    "    print('lmi_median_precision', statistics.median(lmi_precisions))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e079937c79d62fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(queries_evaluated)\n",
    "indexes = [i for i, val in enumerate(queries_precision) if val == 0.0]\n",
    "print(\"indexes with zero precision: \", indexes)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea49bea8007dc5a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_precision = sum(queries_precision) / len(queries_precision)\n",
    "print(\"Average precision: \", avg_precision)\n",
    "print(\"Median precision: \", statistics.median(queries_precision))\n",
    "print(\"Wall Time \", wall_time)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30b8aa3c0d37d06b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = f\"./benchmark_{dataset_name}_{total_queries}q.json\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Create a new file with an empty JSON object\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump({}, file)\n",
    "\n",
    "# Now, load the file (which is guaranteed to exist)\n",
    "with open(file_path, 'r') as file:\n",
    "    chroma_results = json.load(file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbb032334d9589ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chroma_results['chroma_lmi'] = {}\n",
    "chroma_results['chroma_lmi']['avg_precision'] = avg_precision\n",
    "chroma_results['chroma_lmi']['median_precision'] = statistics.median(queries_precision)\n",
    "chroma_results['chroma_lmi']['wall time'] = wall_time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd99f9b0f0a3302c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chroma_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6395ebb6170d1b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting up the color palette from seaborn specifically for nice purple and green\n",
    "colors = sns.color_palette(\"husl\", 8)  # Using a color palette with more colors\n",
    "\n",
    "# Creating the pie chart\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.pie([lmi_used_num, bruteforce_used], labels=[\"LMI\", \"Brute Force\"], \n",
    "        colors=[colors[0], colors[3]],  # Selecting nice colors from the palette (Purple and Green)\n",
    "        autopct='%1.1f%%', startangle=140)\n",
    "\n",
    "plt.title('Index Usage')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9749e7058249528"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Plot each point with round, filled markers and ensure x-axis is from 0 to 1, y-axis starts at 0\n",
    "for key, value in chroma_results.items():\n",
    "    color = 'blue' if key == 'chroma_hnsw' else 'purple'\n",
    "    plt.scatter(value['avg_precision'], value['wall time'], label=key, color=color, s=200)  # s is the size of marker\n",
    "\n",
    "# Labeling the axes and title\n",
    "plt.xlabel('Average Precision')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('100 sequentially run queries')\n",
    "plt.xlim(0, 1)  # Ensuring x-axis covers 0 to 1 range\n",
    "if chroma_results.get('chroma_hnsw', False):\n",
    "    plt.ylim(0, max(chroma_results['chroma_hnsw']['wall time'], chroma_results['chroma_lmi']['wall time']) + 10)  # Ensuring y-axis starts at 0\n",
    "else:\n",
    "    plt.ylim(0, max(0, chroma_results['chroma_lmi']['wall time']) + 10)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d04adfbb8524fded"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "21b6d25589e99a97"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
