{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Replace '/path/to/root' with the actual path to the root directory\n",
    "sys.path.append('/storage/brno2/home/zovi/lvd')\n",
    "# sys.path.append('/storage/brno2/home/zovi/lvd/chromadb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c2974-eb50-4246-8826-d328c62c2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import chromadb\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbec181ba889923",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LVD Filtering Benchmark on Keyword dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3926442d4407dbe6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This notebooks allows for conducting basci experoments and visualizations on match keyword filtering dataset.\n",
    "The notebook was orginally designed for [H&M](https://github.com/qdrant/ann-filtering-benchmark-datasets?tab=readme-ov-file) dataset encoded with Efficientnet for experiments. Original the data is from [Kaggle](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the current datetime\n",
    "now = datetime.now()\n",
    "experiment_timestamp = f\"{now.second}_{now.minute}_{now.hour}_{now.day}_{now.month}_{now.year}\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1d61737c7ae55d2"
  },
  {
   "cell_type": "markdown",
   "id": "d170daebdff33cc6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d6fedc0af76997",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_name = \"random_keywords_10k\"\n",
    "dir_path = f\"data/{dataset_name}/\"\n",
    "vectors_path = dir_path + \"vectors.npy\"\n",
    "payloads_path = dir_path + \"payloads.jsonl\"\n",
    "tests_path = dir_path + \"tests.jsonl\"\n",
    "\n",
    "# Load vectors as numpy array\n",
    "vectors = np.load(vectors_path)\n",
    "\n",
    "# Load payloads.jsonl as python list\n",
    "with open(payloads_path, 'r') as file:\n",
    "    payloads = [json.loads(line) for line in file]\n",
    "\n",
    "# Load tests.jsonl as python list\n",
    "with open(tests_path, 'r') as file:\n",
    "    tests = [json.loads(line) for line in file]\n",
    "(vectors.shape, len(payloads), len(tests))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logging"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1c171b648fe5ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_filename = f\"./log_file_{dataset_name}_{experiment_timestamp}.txt\"\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, \n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6f891fd5b7a889d"
  },
  {
   "cell_type": "markdown",
   "id": "ef2096dabd882bb5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Check whether filter have same format and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e0fc89272076f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_payloads(payloads):\n",
    "    \"\"\"\n",
    "    Preprocess payloads replacing None values with the string 'None'.\n",
    "    :param payloads: A list of payload entries\n",
    "    :return: The preprocessed list of payloads\n",
    "    \"\"\"\n",
    "    for payload in payloads:\n",
    "        for key, value in payload.items():\n",
    "            if value is None:\n",
    "                payload[key] = 'None'\n",
    "\n",
    "preprocess_payloads(payloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad2bff653912079",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Metadata Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5785e664424b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(json.dumps(payloads[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9107e202e54b9b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Query Restrictivness Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d6dd0f0379def",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_condition(payloads, condition):\n",
    "    \"\"\"\n",
    "    Apply a given condition to the list of payloads and return the filtered list.\n",
    "    \"\"\"\n",
    "    filtered_payloads = []\n",
    "    filtered_payloads_ids = []\n",
    "\n",
    "    # Check if the condition is 'and' or 'or' and process accordingly\n",
    "    if 'and' in condition:\n",
    "        for i, payload in enumerate(payloads):\n",
    "            if all(payload.get(key, None) == val['match']['value'] for cond in condition['and'] for key, val in cond.items()):\n",
    "                filtered_payloads.append(payload)\n",
    "                filtered_payloads_ids.append(str(i))\n",
    "    elif 'or' in condition:\n",
    "        for i, payload in enumerate(payloads):\n",
    "            if any(payload.get(key, None) == val['match']['value'] for cond in condition['or'] for key, val in cond.items()):\n",
    "                filtered_payloads.append(payload)\n",
    "                filtered_payloads_ids.append(str(i))\n",
    "\n",
    "    return filtered_payloads, filtered_payloads_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31bafa93264986",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ratios = []\n",
    "# \n",
    "# for condition in [tests[i]['conditions'] for i in range(len(tests))]:\n",
    "#     filtered_payloads, _ = apply_condition(payloads, condition)\n",
    "#     ratio = len(filtered_payloads) / len(payloads)\n",
    "#     ratios.append(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835fa8e1d570c4ea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_ratios(ratios):\n",
    "    # Define the intervals (bins)\n",
    "    bins = np.linspace(0.0, 0.5, num=11)  # 11 edges for 10 bins\n",
    "    \n",
    "    # Count the number of ratios in each bin\n",
    "    hist, _ = np.histogram(ratios, bins)\n",
    "    \n",
    "    # Plotting the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(bins[:-1], hist, width=0.05, align='edge', edgecolor='black')\n",
    "    \n",
    "    # Setting the x-axis limits\n",
    "    plt.xlim(0, 0.5)\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Filter Restrictiveness')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Filter Restrictiveness Distribution')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5076fbf9695e8eb6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize_ratios(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd0fb7d06cc701",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get number closest to 0.2 (0.2 is chosen because it represents neither too restrictive nor too permissive condition)\n",
    "# target = 0.2\n",
    "# id_closest_to_target = np.argmin(np.abs(np.array(ratios) - target))\n",
    "# lest_restrictive_condition = tests[id_closest_to_target]['conditions']\n",
    "# _, least_restrictive_condition_ids = apply_condition(payloads, lest_restrictive_condition)\n",
    "# print('Condition with the lowest restrictivness: \\n', lest_restrictive_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter_examples = {int(id_closest_to_target): least_restrictive_condition_ids} "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63376032298f12ae"
  },
  {
   "cell_type": "markdown",
   "id": "34e21cbea68796f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56222316360dc375",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configuration from SISAP 2023 Indexing Challenge - LMI except n_categories\n",
    "index_configuraiton = {\n",
    "    \"lmi:epochs\": \"[200]\",\n",
    "    \"lmi:model_types\": \"['MLP-4']\",\n",
    "    \"lmi:lrs\": \"[0.01]\",\n",
    "    \"lmi:n_categories\": \"[20]\",\n",
    "    \"lmi:kmeans\": \"{'verbose': False, 'seed': 2023}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9509da366caa8d8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "\n",
    "collections = client.list_collections()\n",
    "if collections:\n",
    "    client.delete_collection(collections[0].name)\n",
    "\n",
    "collection_name = \"synthetic_collection\"\n",
    "collection = client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata=index_configuraiton\n",
    ")\n",
    "\n",
    "logging.info(\"Collection Created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e24b81111d7d8e7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# queries_results = perform_queries(total_queries, -1, 0.1, 1)\n",
    "# end = time.time()\n",
    "# wall_time = end - start"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d713ae5f5f6c839d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbc9db45050bb1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "logging.info(f\"Start dataset upload with batch size {batch_size}.\")\n",
    "dataset_size = vectors.shape[0]\n",
    "upload_start = time.time()\n",
    "for i in tqdm(range(0, dataset_size, batch_size), desc=\"Adding documents\"):\n",
    "    collection.add(\n",
    "        embeddings=vectors[i: i + batch_size].tolist(),\n",
    "        metadatas=payloads[i: i + batch_size],\n",
    "        ids=[\n",
    "            str(i) for i in range(i, min(i + batch_size, dataset_size))\n",
    "        ]\n",
    "    )\n",
    "upload_end = time.time()\n",
    "upload_wall_time = upload_end - upload_start\n",
    "logging.info(f\"Dataset upload done with wall time {upload_wall_time} in seconds .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bf6e1c28f8138",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"Start build index.\")\n",
    "build_start = time.time()\n",
    "bucket_assignment = collection.build_index()\n",
    "build_end = time.time()\n",
    "build_wall_time = build_end - build_start\n",
    "logging.info(f\"Index build done with wall time {build_wall_time}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed2aaacd2e28b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_bucket_items(data, highlight_ids=None):\n",
    "    \"\"\"\n",
    "    Plot the number of items in each bucket, with an optional overlay of highlighted items.\n",
    "\n",
    "    Parameters:\n",
    "    data (DataFrame): The data frame containing the 'id', 'bucket', and 'cluster' columns.\n",
    "    highlight_ids (list, optional): List of ids to highlight in the visualization.\n",
    "    \"\"\"\n",
    "    # Count the total number of items in each bucket\n",
    "    bucket_counts = data.groupby('bucket_str').size()\n",
    "    plot_data = bucket_counts.reset_index(name='count')\n",
    "\n",
    "    # Create the bar plot for total items\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    total_bars = sns.barplot(data=plot_data, x='bucket_str', y='count')\n",
    "\n",
    "    # If highlight_ids is provided, overlay highlighted bars\n",
    "    if highlight_ids is not None:\n",
    "        # Filter data to include only highlighted ids\n",
    "        highlighted_data = data[data['id'].isin(highlight_ids)]\n",
    "        highlighted_counts = highlighted_data.groupby('bucket_str').size()\n",
    "        highlighted_plot_data = highlighted_counts.reset_index(name='count')\n",
    "\n",
    "        # Create overlay bar plot for highlighted items\n",
    "        sns.barplot(data=highlighted_plot_data, x='bucket_str', y='count', color='red', alpha=0.7)\n",
    "\n",
    "        # Create custom legend\n",
    "        legend_elements = [Patch(facecolor=total_bars.patches[0].get_facecolor(), label='Total Items in Bucket'),\n",
    "                           Patch(facecolor='red', alpha=0.5, label='Items Satisfying Condition in Bucket')]\n",
    "        plt.legend(handles=legend_elements)\n",
    "\n",
    "    if highlight_ids is not None:\n",
    "        plt.title('Number of Items in Each Bucket For Query With Lowest Restrictiveness')\n",
    "    else:\n",
    "        plt.title('Number of Items in Each Bucket')\n",
    "    plt.xlabel('Bucket')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    # Annotate each bar with the count of elements\n",
    "    for p in total_bars.patches:\n",
    "        bar_height = int(p.get_height())\n",
    "        if bar_height > 0:  # Only annotate bars with a height greater than zero\n",
    "            total_bars.annotate(f'{bar_height}', (p.get_x() + p.get_width() / 2., bar_height),\n",
    "                                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
    "                                textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae278afa9c25fe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_buckets = pd.DataFrame([str(i) for i in range(vectors.shape[0])], columns=[\"id\"])\n",
    "data_buckets['bucket'] = data_buckets['id'].map(lambda x: list(bucket_assignment.get(x, [])))\n",
    "data_buckets['bucket_str'] = data_buckets['bucket'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679bfb637d0049c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot_bucket_items(data_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fcbd522ea5293",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot_bucket_items(data_buckets, highlight_ids=least_restrictive_condition_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b82cb6b26f19",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Query Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea2242aad69bc6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('\\n ------- Query Example ------- \\n')\n",
    "print('Vector: ' + str(tests[0]['query'][:5]).rstrip(\"]\") + \", ... ]\")\n",
    "print('Constraint: ', tests[0]['conditions'])\n",
    "\n",
    "print('\\n ------- Ground Truth For The Query ------- \\n')\n",
    "print('Ground truth: ', tests[0]['closest_ids'])\n",
    "print('Closest scores: '+ str(tests[0]['closest_scores'][:5]).rstrip(\"]\") + \", ... ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293a892b0f2a23",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_condition(input_condition):\n",
    "    output_condition = {}\n",
    "\n",
    "    # Iterate through the keys ('and'/'or') and their list of conditions\n",
    "    for key, conditions in input_condition.items():\n",
    "        output_key = f\"${key}\"\n",
    "        output_conditions = []\n",
    "\n",
    "        # Process each condition in the list\n",
    "        for condition in conditions:\n",
    "            for field, match in condition.items():\n",
    "                # Assume 'match' is always present as per input format\n",
    "                value = match['match']['value']\n",
    "                output_conditions.append({field: value})\n",
    "\n",
    "        # If there's only one condition in 'and'/'or', do not use '$and'/'$or'\n",
    "        if len(output_conditions) == 1 and key in ['and', 'or']:\n",
    "            output_condition = output_conditions[0]\n",
    "        else:\n",
    "            output_condition[output_key] = output_conditions\n",
    "\n",
    "    return output_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eaac39521a7c7d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_condition_to_simple_dict(condition):\n",
    "    key = list(condition['and'][0].keys())[0]  # Extract key from the first item\n",
    "    value = condition['and'][0][key]['match']['value']  # Extract value from the nested structure\n",
    "    return {key: value}\n",
    "\n",
    "def calculate_precision(relevant_ids, retrieved_ids):\n",
    "    # If there are no relevant IDs and no retrieved IDs, precision is 1\n",
    "    if len(relevant_ids) == 0 and len(retrieved_ids) == 0:\n",
    "        return 1\n",
    "    \n",
    "    retrieved_ids = set(map(int, retrieved_ids))\n",
    "    relevant_ids = set(relevant_ids)\n",
    "    true_positives = len(relevant_ids & retrieved_ids)\n",
    "    \n",
    "    return true_positives / len(retrieved_ids) if retrieved_ids else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152b234426aebc1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_queries(total_queries, constraint_weight, bruteforce_threshold, n_buckets=1, search_until_bucket_not_empty=False):\n",
    "    queries_results = []\n",
    "    \n",
    "    for query_id in range(total_queries):\n",
    "        test_query_object = tests[query_id]\n",
    "        start = time.time()\n",
    "        results = collection.query(\n",
    "            query_embeddings=test_query_object[\"query\"],\n",
    "            include=[\"metadatas\"],\n",
    "            where=convert_condition(test_query_object[\"conditions\"]),\n",
    "            n_results=25,\n",
    "            n_buckets=n_buckets,\n",
    "            constraint_weight=constraint_weight,\n",
    "            bruteforce_threshold=bruteforce_threshold,\n",
    "            search_until_bucket_not_empty=search_until_bucket_not_empty\n",
    "        )\n",
    "        end = time.time()\n",
    "        wall_time = end - start\n",
    "        results['wall_time'] = wall_time\n",
    "        \n",
    "        queries_results.append(results)\n",
    "        \n",
    "    return queries_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbdef6d3bed8ad6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Constraint Parameter Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info(\"Start parameter benchmark.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b427ad660e2ca36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "queries_per_vis = 1000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adb41148ec9448c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45b49aa037d42d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percision_per_restrictiveness(vis_queries_filter_restrictiveness, vis_queries_precision_lmi, constrint_weight, bruteforce_threshold):\n",
    "    # Create a DataFrame for easy plotting\n",
    "    data = pd.DataFrame({\n",
    "        'Filter Restrictiveness': vis_queries_filter_restrictiveness,\n",
    "        'Precision LMI': vis_queries_precision_lmi\n",
    "    })\n",
    "    \n",
    "    bin_edges = np.arange(-0.05, 0.55, 0.1) # six bins centered around 0.0, 0.1, ..., 0.5\n",
    "    \n",
    "    # Cut the data into bins\n",
    "    bin_indices = pd.cut(data['Filter Restrictiveness'], bins=bin_edges, include_lowest=True, labels=False)\n",
    "    \n",
    "    # Initialize bin_medians array with zeros (or any default value) for each bin\n",
    "    bin_medians = np.zeros(len(bin_edges) - 1)\n",
    "\n",
    "    # Calculate the median for each bin and update the corresponding index in bin_medians\n",
    "    grouped_data = data.groupby(bin_indices)['Precision LMI']\n",
    "    for i in range(len(bin_edges) - 1):\n",
    "        if i in grouped_data.groups:\n",
    "            bin_medians[i] = grouped_data.get_group(i).median()\n",
    "        else:\n",
    "            bin_medians[i] = 0  # Default value for bins with no data\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot the histogram in the first subplot\n",
    "    ax1.bar(bin_edges[:-1], bin_medians, width=0.1, align='edge', edgecolor='black')\n",
    "    ax1.set_xlabel('Filter Restrictiveness')\n",
    "    ax1.set_ylabel('Median Precision LMI')\n",
    "    ax1.set_title(f'Median Precision LMI by Filter Restrictiveness With CW {constrint_weight} and BT {bruteforce_threshold}')\n",
    "\n",
    "    # Plot the scatter plot in the second subplot\n",
    "    ax2.scatter(data['Filter Restrictiveness'], data['Precision LMI'], alpha=0.7)\n",
    "    ax2.set_xlabel('Filter Restrictiveness')\n",
    "    ax2.set_ylabel('Precision LMI')\n",
    "    ax2.set_title('Scatter Plot of Precision LMI vs Filter Restrictiveness')\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e041e19432de8d8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cw_test = {}\n",
    "cw_grid = [-1, 0.0, 0.25, 0.5,  0.75, 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151802d543acad9b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bruteforce_for_cws = 0.0\n",
    "\n",
    "for cw in cw_grid:\n",
    "    vis_queries_evaluated = perform_queries(queries_per_vis, cw, bruteforce_for_cws, 1, False)\n",
    "    \n",
    "    vis_lmi_indexes = []\n",
    "    \n",
    "    for i, result in enumerate(vis_queries_evaluated):\n",
    "        if not result['bruteforce_used']:\n",
    "            vis_lmi_indexes.append(i)\n",
    "    \n",
    "    # I want to evaluate only queries that used LMI\n",
    "    # With bruteforce_for_cws=0.0 this will always pass\n",
    "    # assert len(vis_lmi_indexes) >= 100\n",
    "    # vis_lmi_indexes = vis_lmi_indexes[:100]\n",
    "    \n",
    "    vis_queries_precision = list((calculate_precision(tests[i][\"closest_ids\"], result['ids'][0]) for i, result in enumerate(vis_queries_evaluated)))\n",
    "    vis_queries_filter_restrictiveness = list(result['filter_restrictiveness'] for result in vis_queries_evaluated)\n",
    "    \n",
    "    vis_queries_precision_lmi = [vis_queries_precision[i] for i in vis_lmi_indexes]\n",
    "    vis_queries_filter_restrictiveness = [vis_queries_filter_restrictiveness[i] for i in vis_lmi_indexes]\n",
    "    \n",
    "    # percision_per_restrictiveness(vis_queries_filter_restrictiveness, vis_queries_precision_lmi, cw, 0.0)\n",
    "    cw_test[f\"cw: {cw}\"] = sum(vis_queries_precision_lmi)/len(vis_queries_precision_lmi)\n",
    "    \n",
    "# # Extracting keys and values\n",
    "# keys = list(cw_test.keys())\n",
    "# values = list(cw_test.values())\n",
    "# \n",
    "# # Creating the bar chart\n",
    "# plt.bar(keys, values, color=['blue', 'green', 'purple', 'orange'])\n",
    "# \n",
    "# # Adding labels and title\n",
    "# plt.xlabel('Hyperparameter')\n",
    "# plt.ylabel('Average Precision')\n",
    "# plt.title('Constraint weight')\n",
    "# \n",
    "# # Displaying the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b895505ca5f69",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cw_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d816efe7e106811c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Bruteforce Threshold Parameter Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2d87069e115af",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_data = {}\n",
    "\n",
    "for bruteforce_param in [0, 1]:\n",
    "    vis_queries_evaluated = perform_queries(queries_per_vis, 0.5, bruteforce_param, 1, False)\n",
    "\n",
    "    vis_lmi_indexes = []\n",
    "    for i, result in enumerate(vis_queries_evaluated):\n",
    "            vis_lmi_indexes.append(i)\n",
    "\n",
    "    # assert len(vis_lmi_indexes) >= 100\n",
    "\n",
    "    vis_queries_wall_time = [result['wall_time'] for result in vis_queries_evaluated]\n",
    "    vis_queries_wall_time = [vis_queries_wall_time[i] for i in vis_lmi_indexes]\n",
    "\n",
    "    vis_queries_filter_restrictiveness = [result['filter_restrictiveness'] for result in vis_queries_evaluated]\n",
    "    vis_queries_filter_restrictiveness = [vis_queries_filter_restrictiveness[i] for i in vis_lmi_indexes]\n",
    "\n",
    "    data_wall_time_per_restrictiveness = pd.DataFrame({\n",
    "        'Filter Restrictiveness': vis_queries_filter_restrictiveness,\n",
    "        'Wall Time': vis_queries_wall_time\n",
    "    })\n",
    "\n",
    "    bin_edges = np.arange(-0.05, 0.55, 0.1)\n",
    "    bin_indices = pd.cut(data_wall_time_per_restrictiveness['Filter Restrictiveness'], bins=bin_edges, include_lowest=True, labels=False)\n",
    "\n",
    "    # Initialize bin_medians array with zeros for each bin\n",
    "    bin_medians = np.zeros(len(bin_edges) - 1)\n",
    "\n",
    "    # Calculate the median for each bin and update the corresponding index in bin_medians\n",
    "    grouped_data = data_wall_time_per_restrictiveness.groupby(bin_indices)['Wall Time']\n",
    "    for i in range(len(bin_edges) - 1):\n",
    "        if i in grouped_data.groups:\n",
    "            bin_medians[i] = grouped_data.get_group(i).median()\n",
    "        else:\n",
    "            bin_medians[i] = 0  # Default value for bins with no data\n",
    "\n",
    "    # Store histogram data for overlay plot\n",
    "    hist_data[bruteforce_param] = [(bin_edges[:-1] + 0.05).tolist(), bin_medians.tolist()]\n",
    "\n",
    "    # # Original figures within the loop\n",
    "    # fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    # axs[0].bar(bin_edges[:-1], bin_medians, width=0.1, align='edge', edgecolor='black')\n",
    "    # axs[0].set_xlabel('Filter Restrictiveness')\n",
    "    # axs[0].set_ylabel('Median Wall Time')\n",
    "    # axs[0].set_title(f'Median Wall Time by Filter Restrictiveness for Bruteforce Threshold {bruteforce_param}')\n",
    "    # \n",
    "    # axs[1].scatter(data_wall_time_per_restrictiveness['Filter Restrictiveness'], data_wall_time_per_restrictiveness['Wall Time'])\n",
    "    # axs[1].set_xlabel('Filter Restrictiveness')\n",
    "    # axs[1].set_ylabel('Wall Time (seconds)')\n",
    "    # axs[1].set_title(f'Scatter Plot of Filter Restrictiveness vs Wall Time for Bruteforce Threshold {bruteforce_param}')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "# # Overlayed line charts after the loop\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# \n",
    "# # Line chart for bruteforce_param=0 with a distinct color\n",
    "# plt.plot(hist_data[0][0], hist_data[0][1], color='red', marker='o', linestyle='-', label='Bruteforce Threshold 0')\n",
    "# \n",
    "# # Line chart for bruteforce_param=1 with a different distinct color\n",
    "# plt.plot(hist_data[1][0], hist_data[1][1], color='green', marker='o', linestyle='-', label='Bruteforce Threshold 1')\n",
    "# \n",
    "# plt.xlabel('Filter Restrictiveness')\n",
    "# plt.ylabel('Median Wall Time')\n",
    "# plt.title('Overlayed Line Charts of Median Wall Time by Filter Restrictiveness')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6056e32a6c99357"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info(\"Parameter benchmark done.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0881c556985f017"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Store Hyperparameters Visualization Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e9c97f1bc326af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info(\"Start store results.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30b25e8d74fa038"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_dir = f'./results/{dataset_name}/{experiment_timestamp}/'\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "for vis_name, vis_object in [\n",
    "    (\"cw_test\", cw_test), \n",
    "    (\"bruteforce_test\", hist_data), \n",
    "    # (\"ratios\", ratios), \n",
    "    (\"data_buckets\", data_buckets.values.tolist()),\n",
    "    # (\"filter_examples\", filter_examples)\n",
    "]:\n",
    "    file_path = f\"benchmark_{dataset_name}_{vis_name}.json\"\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(experiment_dir + file_path, 'w') as file:\n",
    "            json.dump(vis_object, file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1b786148c2be78f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info(\"Store results done.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6670c4a9ad4af1ac"
  },
  {
   "cell_type": "markdown",
   "id": "1e367d7ff08b7366",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### DEPRECATED: Benchmark Constraint Search"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Note: this part is no longer used for benchmarking, since that is now handled in Vector DB Benchmar repository"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9d17122ed841ad4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627775f826c435",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_queries = 1\n",
    "# \n",
    "# start = time.time()\n",
    "# queries_results = perform_queries(total_queries, -1, 0.1, 1)\n",
    "# end = time.time()\n",
    "# wall_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca448138a514f1d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a70fa21da6717",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# queries_precision = list((calculate_precision(tests[i][\"closest_ids\"], result['ids'][0]) for i, result in enumerate(queries_results)))\n",
    "# lmi_queries_indexes = []\n",
    "# for i, result in enumerate(queries_results):\n",
    "#     if not result['bruteforce_used']:\n",
    "#         lmi_queries_indexes.append(i)\n",
    "# lmi_used_num = len(lmi_queries_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e079937c79d62fb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('Number of times LMI was used', len(lmi_queries_indexes))\n",
    "# bruteforce_used = total_queries - lmi_used_num\n",
    "# \n",
    "# lmi_precisions = [queries_precision[i] for i in lmi_queries_indexes]\n",
    "# if len(lmi_precisions) > 0:\n",
    "#     print('lmi_average_precision', sum(lmi_precisions) / len(lmi_precisions))\n",
    "#     print('lmi_median_precision', statistics.median(lmi_precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea49bea8007dc5a9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # print(queries_evaluated)\n",
    "# indexes = [i for i, val in enumerate(queries_precision) if val == 0.0]\n",
    "# print(\"indexes with zero precision: \", indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8aa3c0d37d06b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# avg_precision = sum(queries_precision) / len(queries_precision)\n",
    "# print(\"Average precision: \", avg_precision)\n",
    "# print(\"Median precision: \", statistics.median(queries_precision))\n",
    "# print(\"Wall Time \", wall_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb032334d9589ec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file_path = f\"./benchmark_{dataset_name}_{total_queries}q.json\"\n",
    "\n",
    "# # Check if the file exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Create a new file with an empty JSON object\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         json.dump({}, file)\n",
    "# \n",
    "# # Now, load the file (which is guaranteed to exist)\n",
    "# with open(file_path, 'r') as file:\n",
    "#     chroma_results = json.load(file)\n",
    "# chroma_results = {'chroma_lmi': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99f9b0f0a3302c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chroma_results['chroma_lmi']['avg_precision'] = avg_precision\n",
    "# chroma_results['chroma_lmi']['median_precision'] = statistics.median(queries_precision)\n",
    "# chroma_results['chroma_lmi']['wall time'] = wall_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6395ebb6170d1b3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chroma_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9749e7058249528",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Setting up the color palette from seaborn specifically for nice purple and green\n",
    "# colors = sns.color_palette(\"husl\", 8)  # Using a color palette with more colors\n",
    "# \n",
    "# # Creating the pie chart\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.pie([lmi_used_num, bruteforce_used], labels=[\"LMI\", \"Brute Force\"], \n",
    "#         colors=[colors[0], colors[3]],  # Selecting nice colors from the palette (Purple and Green)\n",
    "#         autopct='%1.1f%%', startangle=140)\n",
    "# \n",
    "# plt.title('Index Usage')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04adfbb8524fded",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "# \n",
    "# # Plot each point with round, filled markers and ensure x-axis is from 0 to 1, y-axis starts at 0\n",
    "# for key, value in chroma_results.items():\n",
    "#     color = 'blue' if key == 'chroma_hnsw' else 'purple'\n",
    "#     plt.scatter(value['avg_precision'], value['wall time'], label=key, color=color, s=200)  # s is the size of marker\n",
    "# \n",
    "# # Labeling the axes and title\n",
    "# plt.xlabel('Average Precision')\n",
    "# plt.ylabel('Seconds')\n",
    "# plt.title('100 sequentially run queries')\n",
    "# plt.xlim(0, 1)  # Ensuring x-axis covers 0 to 1 range\n",
    "# if chroma_results.get('chroma_hnsw', False):\n",
    "#     plt.ylim(0, max(chroma_results['chroma_hnsw']['wall time'], chroma_results['chroma_lmi']['wall time']) + 10)  # Ensuring y-axis starts at 0\n",
    "# else:\n",
    "#     plt.ylim(0, max(0, chroma_results['chroma_lmi']['wall time']) + 10)\n",
    "# plt.legend()\n",
    "# \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6d25589e99a97",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
