{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LVD Usage With RAG Architecture"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5cea99e967b66f0"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "!pip install -q openai\n",
    "!pip install -q langchain\n",
    "!pip install -q datasets==2.14.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T18:58:16.364999600Z",
     "start_time": "2024-04-18T18:58:06.492240600Z"
    }
   },
   "id": "e90a178a07cc131a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from openai import OpenAI\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import chromadb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T18:58:18.785730400Z",
     "start_time": "2024-04-18T18:58:16.361157900Z"
    }
   },
   "id": "b43438f42610b84c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize OpenAI API client"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28b0f7c857e241bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the purpose of this demo I will use the OpenAI it does not require setting up local LLM mode. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1fbb9f7a2e8dedb"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "API_KEY = \"your-api-key-here\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T18:58:18.800437800Z",
     "start_time": "2024-04-18T18:58:18.786891800Z"
    }
   },
   "id": "fb25e324ff075ed5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T18:58:19.079779500Z",
     "start_time": "2024-04-18T18:58:18.801436700Z"
    }
   },
   "id": "31fea64ce5d880f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LVD Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aac959305f029cf8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this demo a dataset generated through OpenAI consisting of 10 documents representing the news from different domains after 2021."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "852e631ffbe7578e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "documents = [\n",
    "  \"The 'Right to Repair' movement had successfully influenced legislation in the EU and USA, mandating manufacturers to make electronic devices easier to repair.\",\n",
    "  \"Pakistan faced a catastrophic natural disaster in the summer of 2022, with unprecedented flooding that affected millions of people and caused extensive economic damage\",\n",
    "  \"Taylor Swift's most recent album is called 'Midnights'. It explores themes of introspection, insecurity, and personal growth during sleepless nights.\",\n",
    "  \"OpenAI's GPT-4 significantly advances reasoning capabilities, offering enhanced fine-tuning options and robust multilingual support.\",\n",
    "  \"Google's 53-qubit quantum processor marks a milestone in quantum computing, showcasing practical quantum supremacy.\",\n",
    "  \"The Apple Vision Pro Headset, unveiled in 2023 by Apple, is a mixed reality device that combines augmented and virtual reality technologies. It features advanced spatial audio, 8K displays for each eye, and seamless integration with other Apple products.\",\n",
    "  \"Meta's Quest 3 virtual reality headset features improved hand tracking technology, higher resolution displays, and AI-driven interactive environments for an immersive experience.\",\n",
    "  \"Samsung's latest generation of foldable smartphones boasts ultra-thin glass technology, enhancing both durability and display quality.\",\n",
    "  \"Sony's PlayStation 6 incorporates AI-driven gameplay enhancement features, real-time ray tracing graphics, and a novel virtual reality component.\",\n",
    "  \"Global inflation rates surged in 2022 due to supply chain disruptions and increased energy prices, significantly impacting the cost of living worldwide.\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T18:58:19.095236500Z",
     "start_time": "2024-04-18T18:58:19.070224400Z"
    }
   },
   "id": "4a87eb6422ff9e1c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddingFunction(api_key=API_KEY, model_name='text-embedding-3-small')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T18:58:19.347401800Z",
     "start_time": "2024-04-18T18:58:19.083472300Z"
    }
   },
   "id": "d9accd793aba262"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(\n",
    "  name='news', \n",
    "  embedding_function=embedding_function,\n",
    "  metadata={\n",
    "    \"lmi:n_categories\": f\"[2]\",\n",
    "  }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T18:58:21.506916400Z",
     "start_time": "2024-04-18T18:58:19.347401800Z"
    }
   },
   "id": "66b3580a6ced6611"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            LMI Build Config:\n",
      "            {\n",
      "                clustering_algorithms: [<function cluster at 0x000001A25E1F55E0>],\n",
      "                epochs: [200],\n",
      "                model_types: ['MLP'],\n",
      "                learning_rate: [0.01],\n",
      "                n_categories: [2],\n",
      "            }\n",
      "             \n"
     ]
    }
   ],
   "source": [
    "collection.add(\n",
    "    ids=[f\"id{i}\" for i in range(len(documents))],\n",
    "    documents=documents\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T18:58:22.506256400Z",
     "start_time": "2024-04-18T18:58:21.507905400Z"
    }
   },
   "id": "98f287f70a6ae014"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS Kmeans parameters {'verbose': False, 'seed': 2023}\n",
      "LMI built with n_buckets_in_index: 2\n",
      "Time taken to build: 0.7161502838134766; Time taken to cluster: 0.17160582542419434\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'id5': [1],\n 'id4': [1],\n 'id7': [0],\n 'id6': [1],\n 'id9': [1],\n 'id8': [1],\n 'id2': [0],\n 'id1': [0],\n 'id3': [1],\n 'id0': [0]}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.build_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T18:58:23.245509700Z",
     "start_time": "2024-04-18T18:58:22.502548Z"
    }
   },
   "id": "1edf53d3c9efaf5a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RAG Pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63b7a84d921f6b48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this demo I use `gpt-3.5-turbo`from [OpenAI](https://platform.openai.com/docs/models/gpt-3-5-turbo) which have training data up to September 2021.\n",
    "Thee `llm_pipeline` represent bare-bones call to the OpenAI API with the user prompt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "399595cd914a4088"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def llm_pipeline(prompt, context = \"\"):\n",
    "    additional_context = f\"Answer user prompt based on the following context: {context}.\" if context else \"\"\n",
    "    system_prompt = f\"You are generic chatbot assitant. {additional_context}\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ],\n",
    "      max_tokens=100,\n",
    "      temperature=0.0,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T19:02:08.424810100Z",
     "start_time": "2024-04-18T19:02:08.407743500Z"
    }
   },
   "id": "b212349a4af3bb23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bellow is the definition of the `rag_pipeline` that represents the simple RAG architecture. It takes the user prompt and uses it to perform a search query in the LVD.\n",
    "The result of the search query represents the context that the LLM model will receive. Thanks to this context, the LLM will be able to generate up to date answer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f205d051d731c57"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def rag_pipeline(prompt):\n",
    "    results = collection.query(\n",
    "        query_texts=[prompt],\n",
    "        include=[\"documents\"],\n",
    "        n_results=1,\n",
    "        n_buckets=1,\n",
    "    )\n",
    "    context = results['documents'][0][0]\n",
    "    answer = llm_pipeline(prompt, context)\n",
    "    return answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T19:02:11.548861200Z",
     "start_time": "2024-04-18T19:02:11.533293900Z"
    }
   },
   "id": "320f4a6194f7cd15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RAG Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1168ce899dc5dce"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-18 21:02:15,986][INFO ][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Answer: \n",
      " I'm sorry, but as of my last update, there is no information available about a product called Apple Vision Pro being released by Apple. It's possible that it may be a new product that has not been announced yet or it could be a fictional product. I recommend checking Apple's official website or news sources for the most up-to-date information on their product releases. Let me know if you have any other questions or need assistance with anything else.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Describe the product called Apple Vision Pro that was recently released by Apple.\"\n",
    "\n",
    "llm_answer = llm_pipeline(user_prompt)\n",
    "print(\"LLM Answer: \\n\", llm_answer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T19:02:16.006046100Z",
     "start_time": "2024-04-18T19:02:13.208603800Z"
    }
   },
   "id": "c94b9d63e1b8956e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-18 21:02:18,884][INFO ][httpx] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[2024-04-18 21:02:21,398][INFO ][httpx] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: \n",
      " The Apple Vision Pro is a cutting-edge mixed reality headset recently unveiled by Apple. This innovative device combines augmented and virtual reality technologies to provide users with an immersive experience. It boasts advanced spatial audio capabilities, 8K displays for each eye, and seamless integration with other Apple products. The Apple Vision Pro is designed to revolutionize the way users interact with digital content and the world around them.\n"
     ]
    }
   ],
   "source": [
    "rag_answer = rag_pipeline(user_prompt)\n",
    "print(\"RAG Answer: \\n\", rag_answer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T19:02:21.416162Z",
     "start_time": "2024-04-18T19:02:18.558540800Z"
    }
   },
   "id": "4037da18fc68f588"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
